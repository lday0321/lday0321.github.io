<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>lday的博客</title>
  <subtitle>Life, Coding, Funning</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://lday.me/"/>
  <updated>2018-12-02T07:07:42.855Z</updated>
  <id>http://lday.me/</id>
  
  <author>
    <name>lday</name>
    <email>oneday0321@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>如何实现分布式锁</title>
    <link href="http://lday.me/2018/11/18/0022_how_to_do_distributed_lock/"/>
    <id>http://lday.me/2018/11/18/0022_how_to_do_distributed_lock/</id>
    <published>2018-11-18T12:58:14.000Z</published>
    <updated>2018-12-02T07:07:42.855Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;分布式锁服务在分布式系统中是一个非常通用的需求。互联网行业有基于Zookeeper实现分布式锁服务的方案，也有提出基于Redis实现分布式锁服务的方案。企业级应用方面，开源Linux上，Redhat Linux HA套件中提供了&lt;a href=&quot;https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/high_availability_add-on_overview/ch-dlm&quot;&gt;DLM(Distributed Lock Manager)&lt;/a&gt;，商用操作系统OpenVMS也提供了&lt;a href=&quot;http://neilrieck.net/docs/openvms_notes_DLM.html&quot;&gt;DLM&lt;/a&gt;。下面的这篇文章，是我于18年初的时候读到的，最近又重读一遍，作为回顾总结。翻译自Martin Kleppmann的博文：&lt;a href=&quot;https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html&quot;&gt;How to do distributed locking&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="分布式" scheme="http://lday.me/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="redis" scheme="http://lday.me/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>Apache Kafka的分布式系统消防员(Controller Broker)</title>
    <link href="http://lday.me/2018/11/06/0021_apache_kafka_firefighter/"/>
    <id>http://lday.me/2018/11/06/0021_apache_kafka_firefighter/</id>
    <published>2018-11-06T14:52:14.000Z</published>
    <updated>2018-11-18T06:50:17.673Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;作为分布式系统的Kafka，在管理、协调分布式节点，处理各类分布式系统事件时，都依赖于Controller Broker来完成。Controller Broker的工作包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Broker节点上、下线时，处理Broker节点的故障转移。&lt;/li&gt;
&lt;li&gt;Topic新建或删除时，Partition扩容时，处理Partition的分配。&lt;/li&gt;
&lt;li&gt;管理所有Partition的状态机，以及所有Replica的状态机，处理状态机的变化。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以下内容介绍了Controller Broker的具体功能、逻辑，它翻译自：&lt;a href=&quot;https://hackernoon.com/apache-kafkas-distributed-system-firefighter-the-controller-broker-1afca1eae302&quot;&gt;Apache Kafka’s Distributed System Firefighter&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="kafka" scheme="http://lday.me/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>B-Tree数据结构总结</title>
    <link href="http://lday.me/2018/02/21/0020_b_tree_summary/"/>
    <id>http://lday.me/2018/02/21/0020_b_tree_summary/</id>
    <published>2018-02-21T06:04:14.000Z</published>
    <updated>2018-02-24T15:09:11.737Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;对B树的理解一直停留在概念阶段，一直也想了解一些细节。趁着过年这段时间，把《算法导论》关于B树的章节（第18章）整个过了一遍。结合书上的说明，自己实现了一把，留为总结。以下文字内容多摘自《算法导论》，伪代码部分根据我自己的理解添加了注释。&lt;/p&gt;
    
    </summary>
    
    
      <category term="cpp" scheme="http://lday.me/tags/cpp/"/>
    
      <category term="ds_algorithm" scheme="http://lday.me/tags/ds-algorithm/"/>
    
      <category term="b-tree" scheme="http://lday.me/tags/b-tree/"/>
    
  </entry>
  
  <entry>
    <title>共享内存(ipc)的使用</title>
    <link href="http://lday.me/2017/12/17/0019_boost_share_memory_ipc/"/>
    <id>http://lday.me/2017/12/17/0019_boost_share_memory_ipc/</id>
    <published>2017-12-17T15:08:14.000Z</published>
    <updated>2017-12-17T15:53:47.943Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;共享内存，是进程间数据传输的方式之一。数据发送方将数据放入共享内存中，数据接收方则从共享内存中将数据读出，进而完成整个数据的传输。这里我通过使用场景的方式简单总结&lt;code&gt;boost::interprocess share_memory&lt;/code&gt;的使用&lt;/p&gt;
    
    </summary>
    
    
      <category term="cpp" scheme="http://lday.me/tags/cpp/"/>
    
      <category term="boost" scheme="http://lday.me/tags/boost/"/>
    
      <category term="share memory" scheme="http://lday.me/tags/share-memory/"/>
    
      <category term="ipc" scheme="http://lday.me/tags/ipc/"/>
    
  </entry>
  
  <entry>
    <title>C++内存屏障（内存顺序）总结</title>
    <link href="http://lday.me/2017/12/02/0018_cpp_atomic_summary/"/>
    <id>http://lday.me/2017/12/02/0018_cpp_atomic_summary/</id>
    <published>2017-12-02T07:09:14.000Z</published>
    <updated>2017-12-02T07:30:06.925Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;原子操作（atomic）是无锁编程(Lock-Free Programming)的基础。以往，要使用atomic操作，我们一般会使用&lt;a href=&quot;https://gcc.gnu.org/onlinedocs/gcc-4.9.2/gcc/_005f_005fatomic-Builtins.html&quot;&gt;gcc内置的原子操作接口&lt;/a&gt;，或者是基于指定平台硬件指令封装的&lt;a href=&quot;https://github.com/ivmai/libatomic_ops&quot;&gt;atomic库&lt;/a&gt;。c++11直接引入了&lt;a href=&quot;http://en.cppreference.com/w/cpp/atomic&quot;&gt;atomic库&lt;/a&gt;，为c++定义了原子类型操作接口以及内存模型，极大的方便了我们的使用。我尝试通过本文对C++11中内存屏障（内存顺序）的一些基本概念和使用情况进行总结。&lt;/p&gt;
    
    </summary>
    
    
      <category term="cpp" scheme="http://lday.me/tags/cpp/"/>
    
      <category term="concurrency" scheme="http://lday.me/tags/concurrency/"/>
    
      <category term="atomic" scheme="http://lday.me/tags/atomic/"/>
    
  </entry>
  
  <entry>
    <title>Linux下Condition Vairable和Mutext合用的小细节</title>
    <link href="http://lday.me/2017/11/19/0017_condition_variable_and_mutex_together/"/>
    <id>http://lday.me/2017/11/19/0017_condition_variable_and_mutex_together/</id>
    <published>2017-11-19T06:04:14.000Z</published>
    <updated>2017-11-19T06:34:51.815Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;在Linux下合用Condition Variable和Mutex有些小细节。为什么需要这么做，总结于此。&lt;/p&gt;
    
    </summary>
    
    
      <category term="linux" scheme="http://lday.me/tags/linux/"/>
    
      <category term="concurrency" scheme="http://lday.me/tags/concurrency/"/>
    
  </entry>
  
  <entry>
    <title>什么是内存屏障(Memory Barriers)</title>
    <link href="http://lday.me/2017/11/04/0016_what_is_memory_barriers/"/>
    <id>http://lday.me/2017/11/04/0016_what_is_memory_barriers/</id>
    <published>2017-11-04T11:25:14.000Z</published>
    <updated>2017-11-04T10:51:24.701Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;内存屏障是一种底层原语，在不同计算机架构下有不同的实现细节。本文主要在x86_64处理器下，通过Linux及其内核代码来分析和使用内存屏障&lt;/p&gt;
&lt;p&gt;对大多数应用层开发者来说，“内存屏障”（memory barrier）是一种陌生，甚至有些诡异的技术。实际上，他常被用在操作系统内核中，用于实现同步机制、驱动程序等。利用它，能实现高效的无锁数据结构，提高多线程程序的性能表现。本文首先探讨了内存屏障的必要性，之后介绍如何使用内存屏障实现一个无锁唤醒缓冲区（队列），用于在多个线程间进行高效的数据交换。&lt;/p&gt;
    
    </summary>
    
    
      <category term="memory barriers" scheme="http://lday.me/tags/memory-barriers/"/>
    
  </entry>
  
  <entry>
    <title>我们如何在Go中使用gRPC构建C/S结构系统</title>
    <link href="http://lday.me/2017/10/22/0015_How_we_use_gRPC_to_build_a_client_server_system_in_Go/"/>
    <id>http://lday.me/2017/10/22/0015_How_we_use_gRPC_to_build_a_client_server_system_in_Go/</id>
    <published>2017-10-22T15:14:14.000Z</published>
    <updated>2017-10-22T15:37:39.994Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;RPC作为分布式系统节点中较为主流的一种通信方式，因其简单、方便的调用模式而深受开发者的喜爱。gRPC作为google推出的RPC调用框架，更是受到大家的关注。gRPC原生提供了对Golang的支持，最近，我也在关注gRPC的使用，本文是我整理的&lt;em&gt;&lt;a href=&quot;https://medium.com/pantomath/how-we-use-grpc-to-build-a-client-server-system-in-go-dd20045fa1c2&quot;&gt;《How we use gRPC to build a client/server system in Go》&lt;/a&gt;&lt;/em&gt;翻译:&lt;/p&gt;
    
    </summary>
    
    
      <category term="golang" scheme="http://lday.me/tags/golang/"/>
    
      <category term="gRPC" scheme="http://lday.me/tags/gRPC/"/>
    
  </entry>
  
  <entry>
    <title>Kafka数据丢失及最新改进策略</title>
    <link href="http://lday.me/2017/10/08/0014_kafka_data_loss_and_new_mechanism/"/>
    <id>http://lday.me/2017/10/08/0014_kafka_data_loss_and_new_mechanism/</id>
    <published>2017-10-08T14:46:14.000Z</published>
    <updated>2017-10-08T14:46:12.393Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;上周在测试环境，无意间连续把两台kafka的磁盘打爆，导致broker相继挂掉。当我清理完磁盘，重启两台broker后，发现很有意思的现象：&lt;strong&gt;kafka数据丢失！&lt;/strong&gt;从我们的处理日志上， 我们观察到有向一个topic的两个partition，分别写入了3条和7条，共计10条消息。但是，当我们恢复两台broker后，通过命令查看，发现这时该topic两个partition消息数量竟然都是0，而从zk上consumer group记录的信息来看，有cg的确已经消费过该topic的数据，且cg在对应partition上的offset分别为3,7。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kafka" scheme="http://lday.me/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>一次Golang程序延迟过大问题的定位过程</title>
    <link href="http://lday.me/2017/09/13/0013_a_latency_identification_procedure/"/>
    <id>http://lday.me/2017/09/13/0013_a_latency_identification_procedure/</id>
    <published>2017-09-13T14:27:14.000Z</published>
    <updated>2017-09-13T14:43:41.907Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;高吞吐、低延迟，一直是后台程序追求的目标。上周，我对PubSub系统进行了内存泄漏的分析定位，这周进一步对系统处理的延迟进行了分析，找到了引起处理延迟的关键节点。&lt;/p&gt;
    
    </summary>
    
    
      <category term="golang" scheme="http://lday.me/tags/golang/"/>
    
  </entry>
  
  <entry>
    <title>一次Golang程序内存泄漏分析之旅</title>
    <link href="http://lday.me/2017/09/02/0012_a_memory_leak_detection_procedure/"/>
    <id>http://lday.me/2017/09/02/0012_a_memory_leak_detection_procedure/</id>
    <published>2017-09-01T18:49:14.000Z</published>
    <updated>2017-09-01T19:12:01.146Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;最近在开发升级PubSub系统，目标是支持更新版本的kafka（从原来的支持kafka 0.8.2.2升级到支持较新版本的kafka 0.10.1.1）。由于kafka在0.9版本上对consumer group相关的结构进行了&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Client-side+Assignment+Proposal&quot;&gt;重构&lt;/a&gt;，原来使用的基于zk进行rebalance的&lt;a href=&quot;https://github.com/wvanbergen/kafka&quot;&gt;consumer group client:wvanbergen/kafka&lt;/a&gt;已经不再适用。为此，我们调研并最终选用了支持新版kafka consumer rebalance的&lt;a href=&quot;https://github.com/bsm/sarama-cluster&quot;&gt;consumer group client:sarama-cluster&lt;/a&gt;。功能开发已基本结束，目前已进入系统压力测试阶段。&lt;/p&gt;
    
    </summary>
    
    
      <category term="golang" scheme="http://lday.me/tags/golang/"/>
    
  </entry>
  
  <entry>
    <title>Kafka Consumer Rebalance的演进</title>
    <link href="http://lday.me/2017/07/24/0011_kafka_consumer_rebalance_evolution/"/>
    <id>http://lday.me/2017/07/24/0011_kafka_consumer_rebalance_evolution/</id>
    <published>2017-07-24T15:25:14.000Z</published>
    <updated>2017-07-24T15:25:11.742Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Kafka引入了Consumer Group的概念。在一个Consumer Group中的若干Consumer，会按照一定规则（均匀）分配同一topic下的所有partition，各自在相应partition上执行sub工作。当一个Group中有Consumer退出时，Group中的其他Consumer会对topic下的partition进行重新分配，并基于重新分配的结果继续执行sub工作。这个重新分配的过程被称为Rebalance。&lt;/p&gt;
&lt;p&gt;对于Sub方的应用而言，Rebalance过程是透明的，Consumer Group Rebalance实现也经历了几个版本的演进，本文对Rebalance的实现方案进行大致的梳理和总结&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kafka" scheme="http://lday.me/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka Procuder小结</title>
    <link href="http://lday.me/2017/07/15/0010_kafka_producer_analysis_01/"/>
    <id>http://lday.me/2017/07/15/0010_kafka_producer_analysis_01/</id>
    <published>2017-07-15T06:05:05.000Z</published>
    <updated>2017-07-15T06:05:31.209Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;理解Kafka 0.10.0.1版本的Procuder代码，对Producer的整体逻辑进行小结。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kafka" scheme="http://lday.me/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>为什么没有收到预期的413状态码</title>
    <link href="http://lday.me/2017/07/11/0009_why_not_413/"/>
    <id>http://lday.me/2017/07/11/0009_why_not_413/</id>
    <published>2017-07-11T13:21:21.000Z</published>
    <updated>2017-07-11T13:33:00.443Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;HTTP状态码413的含义是请求实体过长，RFC7231对413状态码的定义如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;6.5.11.  413 Payload Too Large&lt;/strong&gt;&lt;br&gt;The 413 (Payload Too Large) status code indicates that the server is refusing to process a request because the request payload is larger than the server is willing or able to process.  The server MAY close the connection to prevent the client from continuing the request.&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="golang" scheme="http://lday.me/tags/golang/"/>
    
      <category term="HTTP" scheme="http://lday.me/tags/HTTP/"/>
    
      <category term="java" scheme="http://lday.me/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>Kafka与传统消息中间件的差异</title>
    <link href="http://lday.me/2017/06/27/0008_kafka_vs_tranditional_mq/"/>
    <id>http://lday.me/2017/06/27/0008_kafka_vs_tranditional_mq/</id>
    <published>2017-06-27T14:21:21.000Z</published>
    <updated>2017-06-27T14:21:59.839Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;因工作关系，之前稍微接触、了解过一些传统的消息中间件（RabbitMQ, ActiveMQ, ZeroMQ, Tibco EMS/FTL, IBM MQ/LLM以及我们自研的消息中间件）。最近的工作则一直是基于Kafka展开的。Kafka的很多设计和理念和传统的消息中间件不太一样，谈谈自己的浅薄认识。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kafka" scheme="http://lday.me/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch总结</title>
    <link href="http://lday.me/2017/06/22/0007_elasticsearch_summary/"/>
    <id>http://lday.me/2017/06/22/0007_elasticsearch_summary/</id>
    <published>2017-06-22T14:03:18.000Z</published>
    <updated>2017-06-22T14:54:20.775Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;前段时间对分布式追踪相关的实现方案进行了一些调研，了解到近期对于大数据的日志检索、分析从原来基于hadoop的实现逐渐过渡到基于es的方案上来。近期在消息审计追踪相关的项目上也尝试的使用了类似的方案。这里对es的一些了解以及常用的一些使用整理于此。&lt;/p&gt;
    
    </summary>
    
    
      <category term="elasticsearch" scheme="http://lday.me/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>多维索引容器(multi_index_container)的使用</title>
    <link href="http://lday.me/2017/03/19/0006_boost-multi-index-container/"/>
    <id>http://lday.me/2017/03/19/0006_boost-multi-index-container/</id>
    <published>2017-03-19T05:34:18.000Z</published>
    <updated>2017-03-19T06:26:50.436Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;C++ STL库为我们提供了vector/list/queue/(unordered)set/(unordered)map等各类容器，这些容器各自有各自的特点。有的提供链表类型的连续访问(vector/list/queue)，有的提供平衡二叉树的数据组织结构(set/map)，有的提供基于Hash的随即定位访问(unordered_set/unordered_map)。但有些时候，单一类型的访问并无法满足我们的需求，例如，有这样一个需求，需要我们实现一个LRU Cache。LRU的意思是：Least Recently Used，即最近最久未被使用的意思。LRU Cache的意思是：如果一个数据在最近一段时间没有被访问到，那么在将来它被访问的可能性也很小，基于这个原则，我们希望该类Cache的空间已经存满数据时，应当把最久没有被访问到的数据淘汰。&lt;/p&gt;
    
    </summary>
    
    
      <category term="cpp" scheme="http://lday.me/tags/cpp/"/>
    
      <category term="boost" scheme="http://lday.me/tags/boost/"/>
    
  </entry>
  
  <entry>
    <title>Golang程序调试工具介绍(gdb vs dlv)</title>
    <link href="http://lday.me/2017/02/27/0005_gdb-vs-dlv/"/>
    <id>http://lday.me/2017/02/27/0005_gdb-vs-dlv/</id>
    <published>2017-02-27T13:26:03.000Z</published>
    <updated>2017-03-12T07:35:15.990Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;通过log库输出日志，我们可以对程序进行异常分析和问题追踪。但有时候，我也希望能有更直接的程序跟踪及定位工具能够帮助我们更方便快捷的追踪、定位问题，最直观的感觉还是使用调试器。Linux平台下，原生的C/C++程序，我们往往使用gdb进行程序调试，切换到Golang，我们同样还是可以使用gdb进行调试。同时我们还可以使用golang实现的调试器dlv进行调试。以下内容是我对gdb以及dlv使用及对比总结&lt;/p&gt;
    
    </summary>
    
    
      <category term="golang" scheme="http://lday.me/tags/golang/"/>
    
  </entry>
  
  <entry>
    <title>细看Go中的切片(slice)</title>
    <link href="http://lday.me/2017/02/25/0004_golang-slice-depth/"/>
    <id>http://lday.me/2017/02/25/0004_golang-slice-depth/</id>
    <published>2017-02-25T04:24:11.000Z</published>
    <updated>2017-03-11T16:17:28.287Z</updated>
    
    <summary type="html">
    
      &lt;h1 id=&quot;讨论群中关于切片的一个问题&quot;&gt;&lt;a href=&quot;#讨论群中关于切片的一个问题&quot; class=&quot;headerlink&quot; title=&quot;讨论群中关于切片的一个问题&quot;&gt;&lt;/a&gt;讨论群中关于切片的一个问题&lt;/h1&gt;&lt;h2 id=&quot;Q1：对slice的append无效&quot;&gt;&lt;a href=&quot;#Q1：对slice的append无效&quot; class=&quot;headerlink&quot; title=&quot;Q1：对slice的append无效&quot;&gt;&lt;/a&gt;Q1：对slice的append无效&lt;/h2&gt;&lt;p&gt;在群里有人提问，下述&lt;a href=&quot;https://play.golang.org/p/jWy3kP2A25&quot;&gt;代码&lt;/a&gt;对slice的append无效&lt;/p&gt;
    
    </summary>
    
    
      <category term="golang" scheme="http://lday.me/tags/golang/"/>
    
  </entry>
  
  <entry>
    <title>基于etcd3的访问序列化及分布式软事务内存</title>
    <link href="http://lday.me/2017/02/01/0003_seri-stm-etcd3/"/>
    <id>http://lday.me/2017/02/01/0003_seri-stm-etcd3/</id>
    <published>2017-02-01T15:20:14.000Z</published>
    <updated>2017-03-11T16:17:14.803Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;&lt;em&gt;本文翻译自&lt;a href=&quot;https://coreos.com/blog/transactional-memory-with-etcd3.html&quot;&gt;Serializability and Distributed Software Transactional Memory with etcd3&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;新的etcd3 API引入了新的更加强大的原语，相比较于etcd2的限制，这些新的原语充分利用了系统的能力。作为评估etcd3性能的一部分，我们花费了很大力气来使用新的API开发分布式的并发算法。&lt;/p&gt;
    
    </summary>
    
    
      <category term="分布式" scheme="http://lday.me/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="etcd" scheme="http://lday.me/tags/etcd/"/>
    
  </entry>
  
</feed>
